# AI-Powered Cloud Masking for Satellite Imagery

## ğŸ“Œ Project Overview

This repository contains an end-to-end solution for **automated cloud detection in satellite imagery** using machine learning and deep learning. The system processes multi-spectral satellite data to generate accurate cloud masks, addressing a critical challenge in remote sensing applications.

## ğŸš€ Key Features

- **Multi-model Architecture**: Implements both deep learning (UNet) and classical (Random Forest, SGD, Ensemble) approaches
- **Advanced Preprocessing**: Handles 4-band satellite imagery with specialized normalization
- **Competition-Ready**: Fully compliant with Kaggle-style submission requirements
- **Reproducible**: Docker support and detailed experiment tracking

## ğŸ›  Installation

### Prerequisites

- Python 3.8+
- NVIDIA GPU (recommended for training)
- [CUDA 11.2](https://developer.nvidia.com/cuda-11.2.0-download-archive) (for GPU acceleration)

### Setup

```bash
# Clone repository
git clone https://github.com/AhmedZahran02/AI-Powered-Cloud-Masking.git
cd AI-Powered-Cloud-Masking

# Install dependencies
pip install -r requirements.txt

# Download dataset (place in data/raw/)
gdown "https://drive.google.com/uc?id=1-cU2qx7XY_lwCC7PKOnnNRkeyRto80gC"
unzip dataset.zip -d data/raw/
```

## ğŸ— Project Structure

```
AI-POWERED-CLOUD-MASKING/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  # Original dataset
â”‚   â”‚   â”œâ”€â”€ data/             # images
â”‚   â”‚   â””â”€â”€ masks/            # Corresponding masks
â”‚   â”œâ”€â”€ processed/            # Processed data after augmentation/normalization
â”‚   â”‚   â”œâ”€â”€ data/             # Training images
â”‚   â”‚   â”‚   â”œâ”€â”€ cloud_free/
â”‚   â”‚   â”‚   â”œâ”€â”€ fully_clouded/
â”‚   â”‚   â”‚   â””â”€â”€ partially_clouded/
â”‚   â”‚   â””â”€â”€ masks/            # Corresponding masks
â”‚   â”‚       â”œâ”€â”€ cloud_free/
â”‚   â”‚       â”œâ”€â”€ fully_clouded/
â”‚   â”‚       â””â”€â”€ partially_clouded/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_analysis.ipynb
â”‚   â”œâ”€â”€ 02_data_preprocessing.ipynb
â”‚   â”œâ”€â”€ 03_classical_model_experiments.ipynb     # Ensemble
â”‚   â”œâ”€â”€ 03_classical_model_experiments_SGD.ipynb # SGD Model
â”‚   â””â”€â”€ 04_deep_learning_experiments.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py             # Configuration parameters
â”‚   â”œâ”€â”€ data_loader.py        # Data loading and augmentation
â”‚   â”œâ”€â”€ preprocessing.py      # Image preprocessing utilities
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ unet.py           # UNet implementation
â”‚   â”‚   â”œâ”€â”€ slim_unet.py      # LightWeight UNet implementation
â”‚   â”‚   â””â”€â”€ ensemble.py  # Classical model
â”‚   â”œâ”€â”€ evaluate.py            # Evaluation metrics
â”‚   â”œâ”€â”€ data_loader.py         # data loading
â”‚   â”œâ”€â”€ config.py              # Configiration
â”‚   â”œâ”€â”€ utils.py               # Helper functions
â”‚   â”œâ”€â”€ rle-encoder-decoder.py # RLE encoder and decoder
â”‚   â””â”€â”€ visualization.py       # Visualization utilities
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/               # Saved model weights
â”‚   â”œâ”€â”€ logs/                 # Training logs
â”‚   â”‚   â””â”€â”€ model_logs.txt    # Records the size of the trained model and the number of operations
â”‚   â””â”€â”€ predictions/          # Prediction outputs
â”œâ”€â”€ run_inference.py          # Inference script for test set
â”œâ”€â”€ run_classical_inference.py          # Inference script for test set
â”œâ”€â”€ test                      # Test Folder for new inference cases
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ Dockerfile                # Docker configuration
â”œâ”€â”€ evaluation_function.py    # evaluate on test set
â”œâ”€â”€ submit_profile.py         # profile model pkl
â”œâ”€â”€ README.md                 # Project documentation
â”œâ”€â”€ Papers/                   # Research Papers
â””â”€â”€ report/                   # Final report assets
    â”œâ”€â”€ figures/              # Report figures
    â””â”€â”€ Report.pdf            # Final PDF report
```

## ğŸ§  Model Performance

| Model    | Dice Coefficient | Inference Time (512 x512) | Parameters |
| -------- | ---------------- | ------------------------- | ---------- |
| UNet     | 0.92             | -                         | 13.4M      |
| SlimUNet | 0.895            | -                         | 1.98M      |
| Ensemble | 0.85             | -                         | -          |

_Metrics on validation set (RTX 3060 GPU)_

## ğŸ’» Usage

### Training

```bash
# Train UNet model (default)
Run the 04_deep_learning_experiments.ipynb notebook
```

### Inference

```bash
# Generate competition submission
python run_inference.py \
    --test_folder test
    --output_csv submission.csv \
    --model_path outputs/models/Slim_Unet_model.pth
    --threshold 0.39473684210526316
```

### Profiling

```bash
python submit_profile.py outputs/models/Looser_Slim_Unet_model.pkl 1 4 512 512
```

### Docker Support

```bash
# Build and run container
docker build -t cloud-masking .
docker run --gpus all -it cloud-masking
```

## ğŸ“Š Sample Results

_Left: Input image | Middle: Ground truth | Right: Model prediction_

## ğŸ“š Documentation

- [Full Project Report](report/ST-Project-Report.pdf)

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
