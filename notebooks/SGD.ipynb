{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f46d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage import uniform_filter, minimum_filter, maximum_filter\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,confusion_matrix, \n",
    "                             f1_score, roc_auc_score, classification_report)\n",
    "import joblib\n",
    "import gc\n",
    "from utils import load_and_normalize_tiff, load_mask\n",
    "import json\n",
    "from visualization import plot_image_and_mask\n",
    "\n",
    "import warnings\n",
    "from rasterio.errors import NotGeoreferencedWarning\n",
    "warnings.filterwarnings(\"ignore\", category=NotGeoreferencedWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configuration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Configuration\n",
    "# ============================================================================\n",
    "class Config:\n",
    "    # Paths\n",
    "    PROCESSED_DATA = Path(\"../data/processed\")\n",
    "    OUTPUT_PATH = Path(\"../outputs\")\n",
    "    MODEL_PATH = OUTPUT_PATH / \"models\"\n",
    "    os.makedirs(MODEL_PATH, exist_ok=True)\n",
    "    \n",
    "    # Training\n",
    "    BATCH_SIZE = 3000  # Pixels per batch\n",
    "    N_EPOCHS = 20\n",
    "    VAL_SPLIT = 0.2\n",
    "    TEST_SPLIT = 0.1\n",
    "    \n",
    "    # Early stopping\n",
    "    EARLY_STOP_PATIENCE = 3  # Number of epochs to wait without improvement\n",
    "    EARLY_STOP_DELTA = 0.001  # Minimum F1 improvement to count as progress\n",
    "    \n",
    "    # Model\n",
    "    SGD_PARAMS = {\n",
    "        'loss': 'modified_huber',  # More robust to outliers than log_loss\n",
    "        'penalty': 'l2',\n",
    "        'alpha': 0.0001,\n",
    "        'learning_rate': 'adaptive',\n",
    "        'eta0': 0.01,\n",
    "        'max_iter': 1,\n",
    "        'class_weight': None\n",
    "    }\n",
    "    \n",
    "    # Feature engineering\n",
    "    SPATIAL_WINDOW = 3  # 3x3 window for spatial features\n",
    "    TEXTURE_WINDOW = 5  # 5x5 window for texture features\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature_engineering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Feature Extraction (Optimized)\n",
    "# ============================================================================\n",
    "def calculate_spectral_indices(image):\n",
    "    \"\"\"Vectorized spectral index calculation with NaN handling\"\"\"\n",
    "    if image.ndim == 3 and image.shape[0] == 4:\n",
    "        red = image[0].astype('float32')\n",
    "        green = image[1].astype('float32')\n",
    "        nir = image[3].astype('float32')\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected image shape: {image.shape}\")\n",
    "    \n",
    "    eps = 1e-6\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        ndvi = (nir - red) / (nir + red + eps)\n",
    "        ndwi = (green - nir) / (green + nir + eps)\n",
    "    \n",
    "    # Replace NaNs/Infs with 0\n",
    "    ndvi = np.nan_to_num(ndvi, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    ndwi = np.nan_to_num(ndwi, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    return {'ndvi': ndvi, 'ndwi': ndwi}\n",
    "\n",
    "def vectorized_spatial_features(band):\n",
    "    \"\"\"Compute spatial features with NaN handling\"\"\"\n",
    "    \n",
    "    mean = uniform_filter(band, size=config.SPATIAL_WINDOW)\n",
    "    mean_sq = uniform_filter(band**2, size=config.SPATIAL_WINDOW)\n",
    "    variance = np.maximum(mean_sq - mean**2, 0.0)  # Ensure non-negative\n",
    "    std = np.sqrt(variance)\n",
    "    \n",
    "    minima = minimum_filter(band, size=config.SPATIAL_WINDOW)\n",
    "    maxima = maximum_filter(band, size=config.SPATIAL_WINDOW)\n",
    "    \n",
    "    return np.stack([mean, std, minima, maxima], axis=-1)\n",
    "\n",
    "def extract_features(image, indices):\n",
    "    \"\"\"Optimized feature extraction for 4x512x512 images\"\"\"\n",
    "    if image.shape != (4, 512, 512):\n",
    "        raise ValueError(f\"Unexpected image shape: {image.shape}\")\n",
    "    \n",
    "    # Transpose to (H, W, C)\n",
    "    image = np.transpose(image, (1, 2, 0))\n",
    "    \n",
    "    # Pre-allocate feature array\n",
    "    n_pixels = 512 * 512\n",
    "    features = np.empty((n_pixels, 22), dtype='float32')  # 4 + 2 + (4*4) = 22\n",
    "    \n",
    "    # Raw bands (4 features)\n",
    "    features[:, 0:4] = image.reshape(-1, 4)\n",
    "    \n",
    "    # Spectral indices (2 features)\n",
    "    features[:, 4] = indices['ndvi'].ravel()\n",
    "    features[:, 5] = indices['ndwi'].ravel()\n",
    "    \n",
    "    # Spatial features (16 features)\n",
    "    for band in range(4):\n",
    "        spatial = vectorized_spatial_features(image[:, :, band])\n",
    "        features[:, 6 + band*4 : 6 + (band+1)*4] = spatial.reshape(-1, 4)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Memory-Efficient Data Pipeline\n",
    "# ============================================================================\n",
    "class CloudDataset:\n",
    "    def __init__(self, image_pairs):\n",
    "        self.image_pairs = image_pairs\n",
    "        self.class_weights = None\n",
    "        \n",
    "    def _stratified_sampling(self, mask, n_samples):\n",
    "        \"\"\"Balanced sampling preserving class ratio\"\"\"\n",
    "        flat_mask = mask.ravel()\n",
    "        cloud_idx = np.where(flat_mask == 1)[0]\n",
    "        clear_idx = np.where(flat_mask == 0)[0]\n",
    "        \n",
    "        n_cloud = int(n_samples * 0.5)\n",
    "        n_clear = n_samples - n_cloud\n",
    "        \n",
    "        sampled_cloud = np.random.choice(cloud_idx, min(n_cloud, len(cloud_idx)), replace=False)\n",
    "        sampled_clear = np.random.choice(clear_idx, min(n_clear, len(clear_idx)), replace=False)\n",
    "        \n",
    "        return np.concatenate([sampled_cloud, sampled_clear])\n",
    "    \n",
    "    def batch_generator(self):\n",
    "        \"\"\"Yields (features, labels) batches with balanced classes\"\"\"\n",
    "        for img_path, mask_path, _ in self.image_pairs:\n",
    "            # print(f\"Processing: {img_path.name}\")\n",
    "            # Load data\n",
    "            image = load_and_normalize_tiff(img_path)\n",
    "            if np.isnan(image).any():\n",
    "                print(f\"Warning: NaNs detected in {img_path}, replacing with 0\")\n",
    "                image = np.nan_to_num(image, nan=0.0)\n",
    "            \n",
    "            mask = load_mask(mask_path)\n",
    "            indices = calculate_spectral_indices(image)\n",
    "            \n",
    "            # Extract features\n",
    "            features = extract_features(image, indices)\n",
    "            features = np.nan_to_num(features, nan=0.0)\n",
    "            labels = mask.ravel()\n",
    "            \n",
    "            # Batch processing\n",
    "            n_batches = len(labels) // config.BATCH_SIZE\n",
    "            for i in range(n_batches):\n",
    "                # Stratified sampling for class balance\n",
    "                batch_idx = self._stratified_sampling(mask, config.BATCH_SIZE)\n",
    "                \n",
    "                X_batch = features[batch_idx]\n",
    "                y_batch = labels[batch_idx]\n",
    "                \n",
    "                # Ensure finite values\n",
    "                assert not np.isinf(features).any(), \"Infinite values detected in features\"\n",
    "                yield X_batch, y_batch\n",
    "                \n",
    "            # Cleanup\n",
    "            del image, mask, features\n",
    "            gc.collect()\n",
    "    \n",
    "    def calculate_class_weights(self):\n",
    "        \"\"\"Compute global class weights\"\"\"\n",
    "        class_counts = {0: 0, 1: 0}\n",
    "        for _, mask_path, _ in self.image_pairs:\n",
    "            mask = load_mask(mask_path)\n",
    "            unique, counts = np.unique(mask, return_counts=True)\n",
    "            for cls, cnt in zip(unique, counts):\n",
    "                class_counts[cls] += cnt\n",
    "        \n",
    "        total = sum(class_counts.values())\n",
    "        self.class_weights = {\n",
    "            0: total / (2 * class_counts[0]),\n",
    "            1: total / (2 * class_counts[1])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73c6796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Metrics Saving\n",
    "# ============================================================================\n",
    "def calculate_metrics(y_true, y_pred, y_proba=None):\n",
    "    \"\"\"Calculate comprehensive metrics\"\"\"\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred),\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'f1': f1_score(y_true, y_pred),\n",
    "        'confusion_matrix': confusion_matrix(y_true, y_pred).tolist(),\n",
    "        'classification_report': classification_report(y_true, y_pred, output_dict=True)\n",
    "    }\n",
    "    \n",
    "    if y_proba is not None:\n",
    "        metrics['roc_auc'] = roc_auc_score(y_true, y_proba)\n",
    "    return metrics\n",
    "\n",
    "def save_metrics(metrics, name, output_dir):\n",
    "    \"\"\"Save metrics to JSON file\"\"\"\n",
    "    metrics_path = output_dir/ \"logs\" / f\"{name}_metrics.json\"\n",
    "    with open(metrics_path, 'w') as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "    print(f\"Saved {name} metrics to {metrics_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fd8236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Inference & Prediction\n",
    "# ============================================================================\n",
    "def predict_full_image(model, image_path, output_path=None):\n",
    "    \"\"\"Predict cloud mask for a full image\"\"\"\n",
    "    # Load and preprocess\n",
    "    image = load_and_normalize_tiff(image_path)\n",
    "    if image.shape != (4, 512, 512):\n",
    "        raise ValueError(f\"Invalid image shape: {image.shape}\")\n",
    "    \n",
    "    # Extract features\n",
    "    indices = calculate_spectral_indices(image)\n",
    "    features = extract_features(image, indices)\n",
    "    \n",
    "    # Predict\n",
    "    proba = model.predict_proba(features)[:, 1]\n",
    "    mask = proba.reshape(512, 512)\n",
    "    \n",
    "    # Post-processing\n",
    "    mask = (mask > 0.5).astype(np.uint8)  # Thresholding\n",
    "    mask = ndimage.binary_closing(mask)  # Remove small holes\n",
    "    \n",
    "    # Save output\n",
    "    if output_path:\n",
    "        plot_image_and_mask(image, mask, output_path)\n",
    "        print(f\"Saved prediction to {output_path}\")\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training_loop",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Training & Validation\n",
    "# ============================================================================\n",
    "def train_model(train_gen_func, val_gen_func, class_weights):\n",
    "    model = SGDClassifier(**{**config.SGD_PARAMS, 'class_weight': class_weights})\n",
    "    best_f1 = 0\n",
    "    all_metrics = {'val': [], 'test': {}}\n",
    "    no_improvement_count = 0  # Track epochs without improvement\n",
    "\n",
    "    for epoch in range(config.N_EPOCHS):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{config.N_EPOCHS}\")\n",
    "        \n",
    "        # Training phase\n",
    "        batch_count = 0\n",
    "        for X_batch, y_batch in tqdm(train_gen_func(), desc=\"Training\", unit=\"batch\"):\n",
    "            model.partial_fit(X_batch, y_batch, classes=[0, 1])\n",
    "            batch_count += 1\n",
    "\n",
    "        print(f\"Trained on {batch_count} batches\")\n",
    "\n",
    "        # Validation phase\n",
    "        val_preds, val_true, val_proba = [], [], []\n",
    "        for X_val, y_val in val_gen_func():\n",
    "            val_preds.extend(model.predict(X_val))\n",
    "            val_true.extend(y_val)\n",
    "            val_proba.extend(model.predict_proba(X_val)[:, 1])\n",
    "\n",
    "        if val_true:\n",
    "            val_metrics = calculate_metrics(val_true, val_preds, val_proba)\n",
    "            all_metrics['val'].append(val_metrics)\n",
    "            \n",
    "            current_f1 = val_metrics['f1']\n",
    "            print(f\"Val F1: {current_f1:.4f} | Best: {best_f1:.4f}\")\n",
    "            \n",
    "            # Early stopping check\n",
    "            if current_f1 > best_f1 + config.EARLY_STOP_DELTA:\n",
    "                best_f1 = current_f1\n",
    "                no_improvement_count = 0\n",
    "                joblib.dump(model, config.MODEL_PATH / \"SGD_best_model.joblib\")\n",
    "                print(\"↑ New best model saved ↑\")\n",
    "            else:\n",
    "                no_improvement_count += 1\n",
    "                print(f\"No improvement ({no_improvement_count}/{config.EARLY_STOP_PATIENCE})\")\n",
    "                \n",
    "                if no_improvement_count >= config.EARLY_STOP_PATIENCE:\n",
    "                    print(f\"Early stopping triggered at epoch {epoch+1}!\")\n",
    "                    break  # Exit epoch loop\n",
    "\n",
    "    # Save final model and metrics (even if stopped early)\n",
    "    joblib.dump(model, config.MODEL_PATH / \"SGD_final_model.joblib\")\n",
    "    save_metrics(all_metrics, 'training', config.OUTPUT_PATH)\n",
    "    \n",
    "    return model, all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "main_pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Main Execution\n",
    "# ============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Prepare datasets\n",
    "    # image_pairs = []\n",
    "    # for category in ['cloud_free', 'partially_clouded', 'fully_clouded']:\n",
    "    #     img_dir = config.PROCESSED_DATA / \"data\" / category\n",
    "    #     mask_dir = config.PROCESSED_DATA / \"masks\" / category\n",
    "        \n",
    "    #     for img_file in img_dir.glob('*.tif'):\n",
    "    #         mask_file = mask_dir / img_file.name\n",
    "    #         if mask_file.exists():\n",
    "    #             image_pairs.append((img_file, mask_file, category))\n",
    "    \n",
    "    from itertools import islice\n",
    "\n",
    "    image_pairs = []\n",
    "    for category in ['cloud_free', 'partially_clouded', 'fully_clouded']:\n",
    "        img_dir = config.PROCESSED_DATA / \"data\" / category\n",
    "        mask_dir = config.PROCESSED_DATA / \"masks\" / category\n",
    "\n",
    "        matched = (\n",
    "            (img_file, mask_dir / img_file.name, category)\n",
    "            for img_file in img_dir.glob('*.tif')\n",
    "            if (mask_dir / img_file.name).exists()\n",
    "        )\n",
    "\n",
    "        image_pairs.extend(islice(matched, 300))\n",
    "\n",
    "    \n",
    "    # 2. Split datasets\n",
    "    train_pairs, val_test_pairs = train_test_split(image_pairs, test_size=config.VAL_SPLIT+config.TEST_SPLIT)\n",
    "    val_pairs, test_pairs = train_test_split(val_test_pairs, test_size=config.TEST_SPLIT/(config.VAL_SPLIT+config.TEST_SPLIT))\n",
    "    \n",
    "    # 3. Create datasets\n",
    "    train_ds = CloudDataset(train_pairs)\n",
    "    val_ds = CloudDataset(val_pairs)\n",
    "    test_ds = CloudDataset(test_pairs)\n",
    "    \n",
    "    # 4. Calculate class weights\n",
    "    train_ds.calculate_class_weights()\n",
    "    \n",
    "    # 5. Train model\n",
    "    print(\"Starting training...\")\n",
    "    model, metrics = train_model(train_ds.batch_generator, \n",
    "                                val_ds.batch_generator, \n",
    "                                train_ds.class_weights)\n",
    "    \n",
    "    # 6. Final test evaluation\n",
    "    print(\"\\nFinal Test Evaluation:\")\n",
    "    y_true, y_pred, y_proba = [], [], []\n",
    "    for X_test, y_test in test_ds.batch_generator():\n",
    "        y_true.extend(y_test)\n",
    "        y_pred.extend(model.predict(X_test))\n",
    "        y_proba.extend(model.predict_proba(X_test)[:, 1])\n",
    "    \n",
    "    test_metrics = calculate_metrics(y_true, y_pred, y_proba)\n",
    "    save_metrics(test_metrics, 'test', config.OUTPUT_PATH)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(f\"ROC AUC: {test_metrics['roc_auc']:.4f}\")\n",
    "\n",
    "    # 7. Example inference\n",
    "    example_image = \"test/data/101885.tif\"\n",
    "    output_mask = config.OUTPUT_PATH / \"predictions\" / \"predicted_mask_101885.png\"\n",
    "    _ = predict_full_image(model, example_image, output_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b48284",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_image = \"test/data/289430.tif\"\n",
    "output_mask = config.OUTPUT_PATH / \"predicted_mask_289430.png\"\n",
    "_ = predict_full_image(model, example_image, output_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601ea3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_image = \"test/data/327408.tif\"\n",
    "output_mask = config.OUTPUT_PATH / \"predicted_mask_327408.png\"\n",
    "_ = predict_full_image(model, example_image, output_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c365b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_image = \"test/data/130726.tif\"\n",
    "output_mask = config.OUTPUT_PATH / \"predicted_mask_130726.png\"\n",
    "_ = predict_full_image(model, example_image, output_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6233f2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_image = \"test/data/140804.tif\"\n",
    "output_mask = config.OUTPUT_PATH / \"predicted_mask_140804.png\"\n",
    "_ = predict_full_image(model, example_image, output_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeec80da",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_image = \"test/data/262934.tif\"\n",
    "output_mask = config.OUTPUT_PATH / \"predicted_mask_262934.png\"\n",
    "_ = predict_full_image(model, example_image, output_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
