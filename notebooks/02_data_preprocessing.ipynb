{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "sys.path.append(os.path.abspath(\"../\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from utils import load_tiff_image,load_mask,load_and_normalize_tiff\n",
    "from config import (\n",
    "    RAW_DATA_PATH,\n",
    "    PROCESSED_DATA_PATH,\n",
    "    PROCESSED_FULLY_CLOUDED_DATA_PATH,\n",
    "    PROCESSED_FREE_CLOUDED_DATA_PATH,\n",
    "    PROCESSED_PARTIALLY_CLOUDED_DATA_PATH,\n",
    "    PROCESSED_FULLY_CLOUDED_MASK_PATH,\n",
    "    PROCESSED_FREE_CLOUDED_MASK_PATH,\n",
    "    PROCESSED_PARTIALLY_CLOUDED_MASK_PATH,\n",
    "    PROCESSED_MISCLASSIFIED_DATA_PATH,\n",
    "    PROCESSED_MISCLASSIFIED_MASK_PATH,\n",
    "    create_dirs,\n",
    "    REVIEW_DIR,\n",
    "    MODEL_PATH\n",
    ")\n",
    "from visualization import plot_image_and_mask,plot_image_and_mask_and_prediction\n",
    "from models.unet import UNet\n",
    "\n",
    "# Set matplotlib to display inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dirs()\n",
    "RELABEL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cloud_coverage(mask):\n",
    "    total_pixels = mask.size\n",
    "    cloud_pixels = np.sum(mask > 0)\n",
    "    return (cloud_pixels / total_pixels) * 100\n",
    "\n",
    "def classify_cloud_coverage(coverage):\n",
    "    if coverage == 0:\n",
    "        return \"cloud_free\"\n",
    "    elif coverage > 80:  # Adjust threshold as needed\n",
    "        return \"fully_clouded\"\n",
    "    else:\n",
    "        return \"partially_clouded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_to_processed(image_path, mask_path, category):\n",
    "    # Determine destination paths based on category\n",
    "    if category == \"cloud_free\":\n",
    "        data_dest = PROCESSED_FREE_CLOUDED_DATA_PATH\n",
    "        mask_dest = PROCESSED_FREE_CLOUDED_MASK_PATH\n",
    "    elif category == \"fully_clouded\":\n",
    "        data_dest = PROCESSED_FULLY_CLOUDED_DATA_PATH\n",
    "        mask_dest = PROCESSED_FULLY_CLOUDED_MASK_PATH\n",
    "    elif category == \"partially_clouded\":\n",
    "        data_dest = PROCESSED_PARTIALLY_CLOUDED_DATA_PATH\n",
    "        mask_dest = PROCESSED_PARTIALLY_CLOUDED_MASK_PATH\n",
    "    else:\n",
    "        data_dest = PROCESSED_MISCLASSIFIED_DATA_PATH\n",
    "        mask_dest = PROCESSED_MISCLASSIFIED_MASK_PATH\n",
    "        \n",
    "    # Copy files\n",
    "    shutil.copy2(image_path, os.path.join(data_dest, os.path.basename(image_path)))\n",
    "    shutil.copy2(mask_path, os.path.join(mask_dest, os.path.basename(mask_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_already_processed(image_filename):\n",
    "    # Check all processed directories for the file\n",
    "    for dir_path in [PROCESSED_FREE_CLOUDED_DATA_PATH, PROCESSED_FULLY_CLOUDED_DATA_PATH, PROCESSED_PARTIALLY_CLOUDED_DATA_PATH]:\n",
    "        if os.path.exists(os.path.join(dir_path, image_filename)):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_images(image_paths, mask_paths, model=None, device=None, samples_per_class=300, \n",
    "                   model_threshold=0.5, similarity_threshold=0.85):\n",
    "    \n",
    "    # Initialize counters\n",
    "    counts = {\n",
    "        \"cloud_free\": 0,\n",
    "        \"fully_clouded\": 0,\n",
    "        \"partially_clouded\": 0,\n",
    "        \"misclassified\": 0  # For failed validations\n",
    "    }\n",
    "    \n",
    "    # Check if model is available\n",
    "    model_available = model is not None and device is not None\n",
    "    \n",
    "    # Initialize lists for each category\n",
    "    cloud_free_images = [img for img, mask in zip(image_paths, mask_paths) \n",
    "                        if classify_cloud_coverage(calculate_cloud_coverage(load_mask(mask))) == \"cloud_free\"]\n",
    "    partially_clouded_images = [img for img, mask in zip(image_paths, mask_paths) \n",
    "                              if classify_cloud_coverage(calculate_cloud_coverage(load_mask(mask))) == \"partially_clouded\"]\n",
    "    fully_clouded_images = [img for img, mask in zip(image_paths, mask_paths) \n",
    "                          if classify_cloud_coverage(calculate_cloud_coverage(load_mask(mask))) == \"fully_clouded\"]\n",
    "\n",
    "    # Process images in order\n",
    "    categories = [\"cloud_free\", \"partially_clouded\", \"fully_clouded\"]\n",
    "    category_lists = [cloud_free_images, partially_clouded_images, fully_clouded_images]\n",
    "    \n",
    "    while any(len(lst) > 0 for lst in category_lists):\n",
    "        for i, category in enumerate(categories):\n",
    "            if counts[category] >= samples_per_class:\n",
    "                continue\n",
    "\n",
    "            if not category_lists[i]:\n",
    "                continue\n",
    "            \n",
    "            img_path = category_lists[i].pop(0)\n",
    "            mask_path = mask_paths[image_paths.index(img_path)]\n",
    "            \n",
    "            if is_already_processed(os.path.basename(img_path)):\n",
    "                continue\n",
    "\n",
    "            # Load data\n",
    "            image = load_tiff_image(img_path)\n",
    "            true_mask = load_mask(mask_path)\n",
    "            true_binary = (true_mask > 0).astype(np.uint8)\n",
    "            coverage = calculate_cloud_coverage(true_mask)\n",
    "            original_category = classify_cloud_coverage(coverage)\n",
    "            \n",
    "            # Automated validation attempt\n",
    "            validated = False\n",
    "            if model_available:\n",
    "                try:\n",
    "                    image_np = load_and_normalize_tiff(img_path)\n",
    "                    image_tensor = torch.from_numpy(image_np).unsqueeze(0).to(device)\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        output = model(image_tensor)\n",
    "                    \n",
    "                    pred_mask = torch.sigmoid(output)\n",
    "                    pred_mask_np = pred_mask.squeeze(0).squeeze(0).cpu().numpy()\n",
    "                    binary_pred_mask = (pred_mask_np > model_threshold).astype(np.uint8)\n",
    "                    \n",
    "                    # Calculate accuracy for full similarity\n",
    "                    correct_pixels = np.sum(true_binary == binary_pred_mask)\n",
    "                    accuracy = correct_pixels / true_mask.size\n",
    "                    \n",
    "                    if accuracy >= similarity_threshold:\n",
    "                        copy_to_processed(img_path, mask_path, original_category)\n",
    "                        counts[original_category] += 1\n",
    "                        print(f\"✅ Auto-validated {os.path.basename(img_path)} as {original_category} (Accuracy: {accuracy:.2f})\")   \n",
    "                    else: \n",
    "                        copy_to_processed(img_path, mask_path, \"misclassified\")\n",
    "                        counts[\"misclassified\"] += 1\n",
    "                        print(f\"❌ Moved to misclassified\")\n",
    "                    validated = True\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"⚠ Model failed on {img_path}: {str(e)}\")\n",
    "            \n",
    "            # Manual validation if automated failed\n",
    "            if not validated:\n",
    "                plot_image_and_mask(image, true_mask, f\"True: {original_category} ({coverage:.2f}%)\")\n",
    "                \n",
    "                response = input(f\"Validate as {original_category}? (y/n/skip/quit): \").lower()\n",
    "                \n",
    "                if response == 'quit':\n",
    "                    print(\"Early termination. Current counts:\", counts)\n",
    "                    return counts\n",
    "                elif response == 'skip':\n",
    "                    continue\n",
    "                elif response == 'y':\n",
    "                    copy_to_processed(img_path, mask_path, original_category)\n",
    "                    counts[original_category] += 1\n",
    "                else:  # 'n' or any other input\n",
    "                    copy_to_processed(img_path, mask_path, \"misclassified\")\n",
    "                    counts[\"misclassified\"] += 1\n",
    "                    print(f\"❌ Moved to misclassified\")\n",
    "            \n",
    "            print(f\"Current counts: {counts}\")\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            # Early exit if all categories are filled\n",
    "            if all(counts[c] >= samples_per_class for c in categories):\n",
    "                break\n",
    "\n",
    "    print(\"\\n=== Final Validation Counts ===\")\n",
    "    for k, v in counts.items():\n",
    "        print(f\"{k:>20}: {v}\")\n",
    "    \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final Validation Counts ===\n",
      "          cloud_free: 514\n",
      "       fully_clouded: 4160\n",
      "   partially_clouded: 4106\n",
      "       misclassified: 1792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cloud_free': 514,\n",
       " 'fully_clouded': 4160,\n",
       " 'partially_clouded': 4106,\n",
       " 'misclassified': 1792}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = None\n",
    "\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    try:\n",
    "        model = UNet(n_channels=4, n_classes=1)\n",
    "        model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        print(\"Model loaded successfully for automated validation\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load model, will use manual validation only: {str(e)}\")\n",
    "        model = None\n",
    "else:\n",
    "    print(\"No model found at specified path, using manual validation\")\n",
    "\n",
    "# Get all image and mask paths\n",
    "image_files = sorted([f for f in os.listdir(os.path.join(RAW_DATA_PATH, \"data\")) if f.endswith(\".tif\")])\n",
    "mask_files = sorted([f for f in os.listdir(os.path.join(RAW_DATA_PATH, \"masks\")) if f.endswith(\".tif\")])\n",
    "\n",
    "# Verify we have matching pairs\n",
    "assert len(image_files) == len(mask_files), \"Mismatch between number of images and masks\"\n",
    "\n",
    "# Create full paths\n",
    "image_paths = [os.path.join(RAW_DATA_PATH, \"data\", f) for f in image_files]\n",
    "mask_paths = [os.path.join(RAW_DATA_PATH, \"masks\", f) for f in mask_files]\n",
    "\n",
    "# Start validation process with model if available\n",
    "validate_images(\n",
    "    image_paths=image_paths,\n",
    "    mask_paths=mask_paths,\n",
    "    model=model,\n",
    "    device=device,\n",
    "    samples_per_class=10000,\n",
    "    model_threshold=0.35,\n",
    "    similarity_threshold=0.85   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relabel_misclassified(data_folder, mask_folder, model, device, model_threshold=0.5, \n",
    "                         confidence_threshold=0.3, agreement_threshold=0.2):\n",
    "    # Get all misclassified files\n",
    "    image_paths = sorted(glob.glob(os.path.join(data_folder, '*.tif')))\n",
    "    mask_paths = sorted(glob.glob(os.path.join(mask_folder, '*.tif')))\n",
    "    \n",
    "    # Initialize counters\n",
    "    results = {\n",
    "        'auto_relabeled': 0,\n",
    "        'needs_review': 0,\n",
    "        'categories': {\n",
    "            'cloud_free': 0,\n",
    "            'partially_clouded': 0,\n",
    "            'fully_clouded': 0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for img_path, mask_path in tqdm(zip(image_paths, mask_paths), total=len(image_paths), desc=\"Processing\"):\n",
    "        # Load data\n",
    "        image = load_and_normalize_tiff(img_path)\n",
    "        true_mask = load_mask(mask_path)\n",
    "        true_binary = (true_mask > 0).astype(np.uint8)\n",
    "        \n",
    "        # Get model prediction\n",
    "        with torch.no_grad():\n",
    "            pred_prob = model(torch.from_numpy(image).unsqueeze(0).to(device)).sigmoid().squeeze().cpu().numpy()\n",
    "        \n",
    "        pred_binary = (pred_prob > model_threshold).astype(np.uint8)\n",
    "        \n",
    "        # Calculate confidence metrics\n",
    "        confidence = np.abs(pred_prob - 0.5).mean()\n",
    "        pixel_agreement = np.mean(true_binary == pred_binary)\n",
    "        \n",
    "        # Determine if extreme case\n",
    "        is_extreme = (confidence < confidence_threshold) or (pixel_agreement < agreement_threshold)\n",
    "        \n",
    "        if not is_extreme and RELABEL:\n",
    "            # Auto-relabel confident cases\n",
    "            new_category = classify_cloud_coverage(calculate_cloud_coverage(pred_binary))\n",
    "            success = replace_and_move(img_path, mask_path, pred_binary, new_category)\n",
    "            if success:\n",
    "                results['auto_relabeled'] += 1\n",
    "                results['categories'][new_category] += 1\n",
    "        else:\n",
    "            # Save case for manual review (with both masks)\n",
    "            success = save_for_review(img_path, mask_path, true_mask, pred_binary)\n",
    "            if success:\n",
    "                results['needs_review'] += 1\n",
    "    \n",
    "    print(\"\\n=== Results ===\")\n",
    "    print(f\"Auto-relabeled: {results['auto_relabeled']}\")\n",
    "    print(f\"Needs review: {results['needs_review']}\")\n",
    "    print(\"Category distribution:\")\n",
    "    for cat, count in results['categories'].items():\n",
    "        print(f\"  {cat}: {count}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def replace_and_move(img_path, mask_path, new_mask, new_category):\n",
    "    try:\n",
    "        # Create target directories\n",
    "        base_dir = PROCESSED_DATA_PATH\n",
    "        new_img_dir = os.path.join(base_dir, 'data', new_category)\n",
    "        new_mask_dir = os.path.join(base_dir, 'masks', new_category)\n",
    "        \n",
    "        # Get filenames\n",
    "        img_name = os.path.basename(img_path)\n",
    "        mask_name = os.path.basename(mask_path)\n",
    "        \n",
    "        # New paths\n",
    "        new_img_path = os.path.join(new_img_dir, img_name)\n",
    "        new_mask_path = os.path.join(new_mask_dir, mask_name)\n",
    "        \n",
    "        # Remove old mask if it exists\n",
    "        if os.path.exists(mask_path):\n",
    "            try:\n",
    "                os.remove(mask_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not remove old mask {mask_path}: {str(e)}\")\n",
    "        \n",
    "        # Move image and save new mask\n",
    "        shutil.move(img_path, new_img_path)\n",
    "        save_mask(new_mask, new_mask_path)\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {img_path}: {str(e)}\")\n",
    "        # Attempt to undo partial operations\n",
    "        if os.path.exists(new_img_path) and not os.path.exists(img_path):\n",
    "            shutil.move(new_img_path, img_path)\n",
    "        return False\n",
    "\n",
    "def save_mask(mask, path):\n",
    "    try:\n",
    "        # Convert to 8-bit (0-255) if needed\n",
    "        if mask.dtype != np.uint8:\n",
    "            mask = (mask * 255).astype(np.uint8)\n",
    "        \n",
    "        # Ensure 2D array\n",
    "        if len(mask.shape) == 3:\n",
    "            mask = mask.squeeze()\n",
    "        \n",
    "        # Create and save image\n",
    "        img = Image.fromarray(mask)\n",
    "        img.save(path, format='TIFF')\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving mask to {path}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def save_for_review(img_path, mask_path, true_mask, pred_mask):\n",
    "    try:\n",
    "        base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "        \n",
    "        # Move original files (not copy)\n",
    "        new_img_path = os.path.join(REVIEW_DIR, f\"{base_name}_image.tif\")\n",
    "        new_true_mask_path = os.path.join(REVIEW_DIR, f\"{base_name}_true_mask.tif\")\n",
    "        \n",
    "        shutil.move(img_path, new_img_path)\n",
    "        shutil.move(mask_path, new_true_mask_path)\n",
    "        \n",
    "        # Save predicted mask (new file)\n",
    "        save_mask(pred_mask, os.path.join(REVIEW_DIR, f\"{base_name}_pred_mask.tif\"))\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error moving to review queue {img_path}: {str(e)}\")\n",
    "        \n",
    "        # Attempt to undo partial moves\n",
    "        if os.path.exists(new_img_path) and not os.path.exists(img_path):\n",
    "            shutil.move(new_img_path, img_path)\n",
    "        if os.path.exists(new_true_mask_path) and not os.path.exists(mask_path):\n",
    "            shutil.move(new_true_mask_path, mask_path)\n",
    "            \n",
    "        return False\n",
    "\n",
    "def manual_review(review_dir):\n",
    "    image_paths = sorted(glob.glob(os.path.join(review_dir, '*_image.tif')))\n",
    "    \n",
    "    for img_path in tqdm(image_paths, desc=\"Manual Review\"):\n",
    "        base_name = os.path.splitext(os.path.basename(img_path))[0].replace('_image', '')\n",
    "        \n",
    "        # Define all related files\n",
    "        true_mask_path = os.path.join(review_dir, f\"{base_name}_true_mask.tif\")\n",
    "        pred_mask_path = os.path.join(review_dir, f\"{base_name}_pred_mask.tif\")\n",
    "        \n",
    "        # Load all components\n",
    "        image = load_tiff_image(img_path)\n",
    "        true_mask = load_mask(true_mask_path)\n",
    "        pred_mask = load_mask(pred_mask_path)\n",
    "        \n",
    "        # Calculate coverages\n",
    "        true_coverage = calculate_cloud_coverage(true_mask)\n",
    "        pred_coverage = calculate_cloud_coverage(pred_mask)\n",
    "        \n",
    "        plot_image_and_mask_and_prediction(image, true_mask, pred_mask, f\"Reviewing {base_name}\")\n",
    "        \n",
    "        # Get user decision\n",
    "        while True:\n",
    "            decision = input(\"Use which mask? (o=original, p=predicted, s=skip, q=quit): \").lower()\n",
    "            \n",
    "            if decision == 'q':\n",
    "                return\n",
    "            elif decision == 's':\n",
    "                break\n",
    "            elif decision in ['o', 'p']:\n",
    "                # Determine which files to keep\n",
    "                selected_mask = true_mask if decision == 'o' else pred_mask\n",
    "                mask_to_delete = pred_mask_path if decision == 'o' else true_mask_path\n",
    "                coverage = true_coverage if decision == 'o' else pred_coverage\n",
    "                new_category = classify_cloud_coverage(coverage)\n",
    "                \n",
    "                # Set up destination\n",
    "                base_dir = os.path.dirname(os.path.dirname(review_dir))\n",
    "                new_img_dir = os.path.join(base_dir, 'data', new_category)\n",
    "                new_mask_dir = os.path.join(base_dir, 'masks', new_category)\n",
    "                os.makedirs(new_img_dir, exist_ok=True)\n",
    "                os.makedirs(new_mask_dir, exist_ok=True)\n",
    "                \n",
    "                # Original filename without suffixes\n",
    "                original_name = f\"{base_name.split('_')[0]}.tif\"\n",
    "                new_img_path = os.path.join(new_img_dir, original_name)\n",
    "                new_mask_path = os.path.join(new_mask_dir, original_name)\n",
    "                \n",
    "                try:\n",
    "                    # Move selected files (not copy)\n",
    "                    shutil.move(img_path, new_img_path)\n",
    "                    save_mask(selected_mask, new_mask_path)\n",
    "                    \n",
    "                    # Delete unused mask file\n",
    "                    if os.path.exists(mask_to_delete):\n",
    "                        os.remove(mask_to_delete)\n",
    "                    \n",
    "                    # Delete the other mask file we didn't use\n",
    "                    remaining_files = glob.glob(os.path.join(review_dir, f\"{base_name}*\"))\n",
    "                    for f in remaining_files:\n",
    "                        try:\n",
    "                            os.remove(f)\n",
    "                        except:\n",
    "                            pass\n",
    "                    \n",
    "                    print(f\"Moved to {new_category} using {'original' if decision == 'o' else 'predicted'} mask\")\n",
    "                    break\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error during file operations: {str(e)}\")\n",
    "                    # Try to undo partial operations\n",
    "                    if os.path.exists(new_img_path) and not os.path.exists(img_path):\n",
    "                        shutil.move(new_img_path, img_path)\n",
    "                    break\n",
    "            else:\n",
    "                print(\"Invalid input. Use o/p/s/q\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(n_channels=4, n_classes=1).to(device)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model.eval()\n",
    "# Auto-process misclassified images\n",
    "results = relabel_misclassified(\n",
    "    data_folder='../data/processed/data/misclassified/',\n",
    "    mask_folder='../data/processed/masks/misclassified/',\n",
    "    model=model,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual review if needed\n",
    "if results['needs_review'] > 0:\n",
    "    manual_review(REVIEW_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
